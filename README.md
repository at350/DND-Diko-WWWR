# DND-Diko-WWWR

We present the Deep Nutrient Deficiency - Dikopshof - Winter Wheat and Winter Rye (DND-Diko-WWWR) dataset, which consists of 1,800 RGB images of winter wheat (WW2020) and 1,800 RGB images of winter rye (WR2021), captured by UAV at the LTFE Dikopshof near Bonn, Germany. The images were annotated with seven types of fertilizer treatments. The dataset is used for image classification. 

## Download
The dataset can be downloaded from [here]().

## Guide for CVPPA workshop challenge 2023


As part of the [8th Workshop on Computer Vision in Plant Phenotyping and Agriculture (CVPPA)](https://cvppa2023.github.io/) at the IEEE/CVF International Conference of Computer Vision (ICCV) 2023, we are organizing a challenge that aims at providing a solution to recognize nutrient deficiencies in winter wheat winter rye. 

In this challenge, one has to provide 




Submission this challenge must in the form of a text file named "predictions.txt" with no headers. Each line in the file should state the image filename, followed by the prediction index (0-6). The file should contain a prediction for each of the test images, corresponding to 467 lines of text. A sample submission file is shown below:

submission.zip
- predictions.txt
```
0001.jpg 5
0002.jpg 0
0003.jpg 6
...
0467.jpg 2
```
An example of submission file can be download [here]. 

### Training and Prediction
We provide a baseline model based on ResNet-50. 

You can now run `python baseline.py` to train the baseline model, and `python baseline.py --dataset_path 'path/to/dataset' --predict 'model_weights.pth.tar'` to perform prediction on the test set and to generate the .json file for submission to Codalab.

### Evaluation
The top-1 accuracy is used. We provide an evaluation script to test your model over the validation set (a subset of the provided training set generated by yourself). Note that his script cannot be used to evaluate models over the testing set, as we do not provide labels for the test set. It is good practice to ensure your predictions work with this script, as the same script is used on the evaluation server. 

Run python evaluate.py with the arguments as described in the script to evaulate the predictions. This creates a *results.txt* file containing the metrics used for the challenge leaderboard.

### Submissions
The evaluation server is hosted using CodaLab. Submitting to the challenge requires a CodaLab account. 
Please find the evaluation server [here](https://codalab.lisn.upsaclay.fr/competitions/13833).
To participate in the challenge, you need to upload a .zip file of the .json file generated by `baseline.py`. 

### FAQ
Q: Can we use any other data than the data provdided?
A: No.

Q: Is it allowed to train our model on the validation data?
A: Yes.

Q: Is data augmentation allowed?
A: Yes, as long as the augmentations are only applied to the provided data.

## Cite
TODO

## License
This dataset follows Creative Commons Attribution Non Commercial Share Alike 4.0 Internation License.